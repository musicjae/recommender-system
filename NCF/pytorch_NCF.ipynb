{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pytorch_NCF.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNE3RKy7tOIrqFb4p49UVmV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/musicjae/recommender-system/blob/main/NCF/pytorch_NCF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yrV9QpNP_txc"
      },
      "source": [
        "#Import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qbxXeJUP8JJs"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.autograd import Variable"
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gWRfJpkU_GNr",
        "outputId": "72f9545f-7578-46e5-ba85-59d5320e3d9f"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5UyYtKat_pjM"
      },
      "source": [
        "#Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gx-lEye1_LNk"
      },
      "source": [
        "dataset = pd.read_csv('/content/drive/My Drive/datasets/Movie_Dataset/ratings_small.csv', header=0)\n",
        "\n",
        "\n",
        "user_id = dataset['userId'].unique().tolist() # ndarray -> list\n",
        "user2i = {u:i for i,u in enumerate(user_id)}\n",
        "i2user = {i:u for i,u in enumerate(user_id)}\n",
        "\n",
        "dataset['user'] = dataset['userId'].map(user2i) # new row 'user'\n",
        "\n",
        "\n",
        "movie_id = dataset['movieId'].unique().tolist()\n",
        "movie2i = {m:i for i,m in enumerate(movie_id)}\n",
        "i2movie = {i:m for i,m in enumerate(movie_id)}\n",
        "\n",
        "dataset['movie'] = dataset['movieId'].map(movie2i)\n",
        "\n",
        "\n",
        "dataset['rating'] = dataset['rating'].values"
      ],
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ROMraJyl_wxj"
      },
      "source": [
        "#train/test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RtthU5LITxOc"
      },
      "source": [
        "pytorch에서는 dataloader에 들어가기 위해 dataframe이 Tensor로 바뀌어야 한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dKH29RXv_yG3",
        "outputId": "62f86ba6-94e0-407d-9f3e-89c9f039c2ba"
      },
      "source": [
        "X_data = dataset[['user','movie']]\n",
        "y_data = dataset['rating']\n",
        "\n",
        "X_data = X_data.values\n",
        "y_data =y_data.values\n",
        "\n",
        "print(X_data.shape)\n",
        "print(y_data.shape)"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(100004, 2)\n",
            "(100004,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0DON44H6OjJM"
      },
      "source": [
        "X_data = torch.from_numpy(X_data)\n",
        "y_data = torch.from_numpy(y_data)"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dPljMkeiUMYJ",
        "outputId": "554bb2ce-f693-4b2a-ffa4-98ef119a447b"
      },
      "source": [
        "print(X_data[:3])\n",
        "print(X_data.shape)\n",
        "print(y_data[:3])"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0, 0],\n",
            "        [0, 1],\n",
            "        [0, 2]])\n",
            "torch.Size([100004, 2])\n",
            "tensor([2.5000, 3.0000, 3.0000], dtype=torch.float64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L2mXbaCTK7_4"
      },
      "source": [
        "##DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NZ6SsJbsIcJd"
      },
      "source": [
        "train_loader = DataLoader(X_data, batch_size=128,shuffle=True, num_workers=16)\n",
        "total_batch = len(train_loader)"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AxYBbz-qWKc6",
        "outputId": "fffe89c5-4f6b-4959-9120-177dff486b94",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cnt=0\n",
        "for i, data in enumerate(train_loader.dataset):\n",
        "    if cnt <5:\n",
        "        a,b = data\n",
        "        print(b)\n",
        "        cnt+=1\n",
        "        print(b.dim())"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(0)\n",
            "0\n",
            "tensor(1)\n",
            "0\n",
            "tensor(2)\n",
            "0\n",
            "tensor(3)\n",
            "0\n",
            "tensor(4)\n",
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gCq-2vjbABLM"
      },
      "source": [
        "#GMF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mY0Xz3yR_CVS"
      },
      "source": [
        "EMBEDDING_SIZE = 32\n",
        "NUM_USERS = len(user2i) # user명에서 i로 변환된것을 사용\n",
        "NUM_ITEMS = len(i2movie) # 인덱스에서 movie로 변환된 것을 사용할 것\n",
        "\n",
        "class GMF(nn.Module):\n",
        "    def __init__(self, NUM_USERS, NUM_ITEMS, Embedding_size=32):\n",
        "        super(GMF,self).__init__()\n",
        "        self.num_users = NUM_USERS\n",
        "        self.num_movies = NUM_ITEMS\n",
        "        self.embedding_size = EMBEDDING_SIZE\n",
        "\n",
        "        self.user_embedding = nn.Embedding(self.num_users, self.embedding_size)\n",
        "        self.user_bias = nn.Embedding(self.num_users, 1)\n",
        "\n",
        "        self.item_embedding = nn.Embedding(self.num_movies, self.embedding_size)\n",
        "        self.item_bias = nn.Embedding(self.num_movies, 1)\n",
        "\n",
        "    def forward(self,inputs):\n",
        "        user_vec = self.user_embedding(inputs)\n",
        "        user_vec = user_vec.view(-1, self.embedding_size) # # n>2 dim -> 2dim\n",
        "        user_bias = self.user_bias(inputs)\n",
        "\n",
        "        item_vec = self.item_embedding(inputs)\n",
        "        item_vec = item_vec.view(-1, self.embedding_size)\n",
        "        item_bias = self.item_bias(inputs)\n",
        "\n",
        "        #dot =  keras.layers.Dot(axes=1)([user_vec, movie_vec])\n",
        "        mat = user_vec * item_vec\n",
        "        x = mat + user_bias + item_bias\n",
        "\n",
        "        return x"
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8MrW79ceApCm"
      },
      "source": [
        "model = GMF(NUM_USERS,NUM_ITEMS,Embedding_size).to(DEVICE)\n",
        "optimizer = torch.optim.Adam(model.parameters(),lr=0.001)\n",
        "criterion = nn.BCELoss()"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uZ7yN8e8DK4L",
        "outputId": "c437c3aa-a5cf-4277-c335-a4a0413f9998"
      },
      "source": [
        "print(model)"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GMF(\n",
            "  (user_embedding): Embedding(671, 32)\n",
            "  (user_bias): Embedding(671, 1)\n",
            "  (item_embedding): Embedding(9066, 32)\n",
            "  (item_bias): Embedding(9066, 1)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "R9KO06VZDM__",
        "outputId": "7250c424-8c96-40f1-a163-57c63db6c367"
      },
      "source": [
        "for epoch in range(10):\n",
        "    print(f'epoch: {epoch}')\n",
        "    for i, data in enumerate(train_loader.dataset):\n",
        "\n",
        "        inputs,labels = data\n",
        "        inputs = torch.as_tensor((inputs,)).cuda()\n",
        "        labels= torch.as_tensor((labels,)).cuda()\n",
        "        print(inputs.dim())\n",
        "        #inputs,labels = Variable(inputs), Variable(labels)\n",
        "\n",
        "        prediction = model(inputs)\n",
        "        loss = criterion(prediction, labels)\n",
        "\n",
        "        print(f'step: {i}\\t loss:{loss.data[0]}')\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch: 0\n",
            "1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-89-e59e673854ca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'step: {i}\\t loss:{loss.data[0]}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_cross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbinary_cross_entropy\u001b[0;34m(input, target, weight, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   2517\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2518\u001b[0m         raise ValueError(\"Using a target size ({}) that is different to the input size ({}) is deprecated. \"\n\u001b[0;32m-> 2519\u001b[0;31m                          \"Please ensure they have the same size.\".format(target.size(), input.size()))\n\u001b[0m\u001b[1;32m   2520\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2521\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mweight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([1, 32])) is deprecated. Please ensure they have the same size."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-PZgvbTIEoHl"
      },
      "source": [
        "def evaluate(model, X_test, y_test):\n",
        "    model.eval()\n",
        "\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        \n",
        "        Test_data = X_test\n",
        "        Label = y_test\n",
        "\n",
        "        output = model(Test_data)\n",
        "        test_loss += criterion(output, Label).item()\n",
        "        prediction = output.max(1,keepdim=True)[1] \n",
        "\n",
        "        correct += prediction.eq(Label.view_as(prediction)).sum().item()\n",
        "\n",
        "    test_loss /= len(X_test)\n",
        "    test_acc = 100*correct/len(X_test)\n",
        "\n",
        "    return test_loss, test_acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJxYuLJCEW6_"
      },
      "source": [
        "EPOCHS = 10\n",
        "for Epoch in range(1, EPOCHS+1):\n",
        "    train(model,X_train, y_train, optimizer)\n",
        "    test_loss, test_accuracy = evaluate(model, X_test, y_test)\n",
        "\n",
        "    print('\\n[EPOCH: {}], \\t TEST LOSS: {:.4f}, \\tTest Accuracy: {:.2f} %\\n'.format(Epoch, test_loss, test_accuracy))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-v1gmyun__PX"
      },
      "source": [
        "#MLP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mM7ra6MF___P"
      },
      "source": [
        "class MLP(nn.Module):"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}